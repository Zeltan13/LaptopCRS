{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f893fa99",
   "metadata": {},
   "source": [
    "# Fine-Tuning GPT-4 with OpenAI API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "294f1589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "#Install necessary libraries\n",
    "#%pip install openai pandas jsonlines --quiet\n",
    "#pip uninstall openai\n",
    "#%pip install openai==0.28\n",
    "#pip install git+https://github.com/openai/openai-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdfa0155",
   "metadata": {},
   "source": [
    "## Import Libraries and Set Up API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "847bf568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\fathan askar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\fathan askar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -ensorflow-intel (c:\\users\\fathan askar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import jsonlines\n",
    "import openai\n",
    "import os\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key='Your OpenAI API Key')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bba6f1f",
   "metadata": {},
   "source": [
    "## Load and Validate Fine-Tuning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3161266c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data validated successfully for conversational fine-tuning.\n"
     ]
    }
   ],
   "source": [
    "#Load and validate the jsonl file for conversational fine-tuning\n",
    "file_path = 'laptop_chat_finetuning_new.jsonl'\n",
    "\n",
    "#FUnction to validate the structure of the jsonl file used for fine-tuning, checking if each entry has a messages key, and inside the messages key it has role and content keys. And inside the role, it should be system, user or assitant.\n",
    "def validate_messages_jsonl(file_path):\n",
    "    with jsonlines.open(file_path) as reader:\n",
    "        for i, obj in enumerate(reader):\n",
    "            if 'messages' not in obj:\n",
    "                raise ValueError(f\"Error in line {i + 1}: Missing 'messages' key.\")\n",
    "            for j, message in enumerate(obj['messages']):\n",
    "                if 'role' not in message or 'content' not in message:\n",
    "                    raise ValueError(f\"Error in line {i + 1}, message {j + 1}: Missing 'role' or 'content' key.\")\n",
    "                if message['role'] not in ['system', 'user', 'assistant']:\n",
    "                    raise ValueError(f\"Error in line {i + 1}, message {j + 1}: Invalid role '{message['role']}'.\")\n",
    "    print(\"Data validated successfully for conversational fine-tuning.\")\n",
    "\n",
    "validate_messages_jsonl(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8466c7fd",
   "metadata": {},
   "source": [
    "## Upload File to OpenAI for Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "654e193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training File ID: file-ANcpYYdVMRzMfXcquEj3hJ\n",
      "Validation File ID: file-96TmZqMy5caaH8n41jJ35s\n"
     ]
    }
   ],
   "source": [
    "#Load the jsonl file into a list of json objects and conevrt reader object into a list\n",
    "with jsonlines.open(file_path) as reader:\n",
    "    data = list(reader)\n",
    "\n",
    "#Split data into training (80%) and validation (20%) for fine-tuning\n",
    "train_size = int(0.8 * len(data))\n",
    "train_data = data[:train_size]\n",
    "validation_data = data[train_size:]\n",
    "\n",
    "#Save the split data into separate files\n",
    "train_file_path = 'laptop_chat_train.jsonl'\n",
    "validation_file_path = 'laptop_chat_validation.jsonl'\n",
    "with jsonlines.open(train_file_path, mode='w') as writer:\n",
    "    writer.write_all(train_data)\n",
    "with jsonlines.open(validation_file_path, mode='w') as writer:\n",
    "    writer.write_all(validation_data)\n",
    "\n",
    "#Upload training and validation file to OpenAI for fine-tuning job\n",
    "train_response = client.files.create(\n",
    "    file=open(train_file_path, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "validation_response = client.files.create(\n",
    "    file=open(validation_file_path, \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "#Access the ID attribute directly from the response object to track the uploaded datasets\n",
    "train_file_id = train_response.id\n",
    "validation_file_id = validation_response.id\n",
    "\n",
    "print(f\"Training File ID: {train_file_id}\")\n",
    "print(f\"Validation File ID: {validation_file_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "880ed469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the file on OpenAI for fine-tuning job\n",
    "response = client.files.create(\n",
    "    file=open(\"laptop_chat_finetuning_reduced.jsonl\", \"rb\"),\n",
    "    purpose=\"fine-tune\"\n",
    ")\n",
    "\n",
    "#Convert the FileObject to a dictionary\n",
    "response_dict = {\n",
    "    \"id\": response.id, #Unique ID assigned by OpenAI\n",
    "    \"bytes\": response.bytes, #File size\n",
    "    \"created_at\": response.created_at, #Time of the uploaded file\n",
    "    \"filename\": response.filename, #Name of the file\n",
    "    \"object\": response.object, #Type of object\n",
    "    \"purpose\": response.purpose, #Purpose of file\n",
    "    \"status\": response.status, #Status of the file to track the fine-tuning\n",
    "    \"status_details\": response.status_details, #Additional status details\n",
    "}\n",
    "\n",
    "#Save the response to a JSON file\n",
    "with open(\"response.json\", \"w\") as json_file:\n",
    "    json.dump(response_dict, json_file, indent=4)\n",
    "\n",
    "#Extract the file ID\n",
    "file_id = response_dict['id']\n",
    "print(f\"File ID: {file_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80b0097",
   "metadata": {},
   "source": [
    "## Start Fine-Tuning Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5e9ca92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job started with ID: ftjob-1EnAOTMHgaW05WUchqTh76Sf\n"
     ]
    }
   ],
   "source": [
    "#Start fine-tuning job with validation file included\n",
    "fine_tune_response = client.fine_tuning.jobs.create(\n",
    "    training_file=train_file_id,\n",
    "    validation_file=validation_file_id,\n",
    "    model=\"gpt-4o-2024-08-06\"\n",
    ")\n",
    "\n",
    "#Convert fine-tuning job response to a dictionary and save it\n",
    "fine_tune_dict = {\n",
    "    \"id\": fine_tune_response.id,\n",
    "    \"created_at\": fine_tune_response.created_at,\n",
    "    \"status\": fine_tune_response.status,\n",
    "    \"model\": fine_tune_response.model,\n",
    "    \"training_file\": fine_tune_response.training_file,\n",
    "    \"validation_file\": fine_tune_response.validation_file,\n",
    "    \"fine_tuned_model\": fine_tune_response.fine_tuned_model,\n",
    "    \"hyperparameters\": {\n",
    "        \"n_epochs\": fine_tune_response.hyperparameters.n_epochs,\n",
    "        \"batch_size\": fine_tune_response.hyperparameters.batch_size,\n",
    "        \"learning_rate_multiplier\": fine_tune_response.hyperparameters.learning_rate_multiplier\n",
    "    },\n",
    "    \"error\": {\n",
    "        \"code\": fine_tune_response.error.code if fine_tune_response.error else None,\n",
    "        \"message\": fine_tune_response.error.message if fine_tune_response.error else None,\n",
    "        \"param\": fine_tune_response.error.param if fine_tune_response.error else None\n",
    "    },\n",
    "    \"result_files\": fine_tune_response.result_files,\n",
    "    \"status_details\": fine_tune_response.status,\n",
    "    \"estimated_finish\": fine_tune_response.estimated_finish,\n",
    "}\n",
    "\n",
    "with open(\"fine_tune_response.json\", \"w\") as json_file:\n",
    "    json.dump(fine_tune_dict, json_file, indent=4)\n",
    "\n",
    "print(f\"Fine-tuning job started with ID: {fine_tune_response.id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fdbb007",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuning job started with ID: ftjob-4wNiRYkDaSJzF42sOnHUoUZZ\n"
     ]
    }
   ],
   "source": [
    "# #Create the fine-tuning job\n",
    "# fine_tune_response = client.fine_tuning.jobs.create(\n",
    "#     training_file=file_id,\n",
    "#     model=\"gpt-4o-2024-08-06\"  #Use GPT-4o version that's suitable for fine-tuning\n",
    "# )\n",
    "\n",
    "# #Convert the FineTuningJob object into a dictionary\n",
    "# fine_tune_dict = {\n",
    "#     \"id\": fine_tune_response.id,\n",
    "#     \"created_at\": fine_tune_response.created_at,\n",
    "#     \"status\": fine_tune_response.status,\n",
    "#     \"model\": fine_tune_response.model,\n",
    "#     \"training_file\": fine_tune_response.training_file,\n",
    "#     \"validation_file\": fine_tune_response.validation_file,\n",
    "#     \"fine_tuned_model\": fine_tune_response.fine_tuned_model,\n",
    "#     \"hyperparameters\": {\n",
    "#         \"n_epochs\": fine_tune_response.hyperparameters.n_epochs,\n",
    "#         \"batch_size\": fine_tune_response.hyperparameters.batch_size,\n",
    "#         \"learning_rate_multiplier\": fine_tune_response.hyperparameters.learning_rate_multiplier\n",
    "#     },\n",
    "#     \"error\": {\n",
    "#         \"code\": fine_tune_response.error.code,\n",
    "#         \"message\": fine_tune_response.error.message,\n",
    "#         \"param\": fine_tune_response.error.param\n",
    "#     },\n",
    "#     \"result_files\": fine_tune_response.result_files,\n",
    "#     \"status_details\": fine_tune_response.status,\n",
    "#     \"estimated_finish\": fine_tune_response.estimated_finish,\n",
    "# }\n",
    "\n",
    "# #Save the fine-tuning job response to a JSON file\n",
    "# with open(\"fine_tune_response.json\", \"w\") as json_file:\n",
    "#     json.dump(fine_tune_dict, json_file, indent=4)\n",
    "\n",
    "# #Extract the fine-tuning job ID\n",
    "# fine_tune_id = fine_tune_response.id\n",
    "# print(f\"Fine-tuning job started with ID: {fine_tune_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193d4a77",
   "metadata": {},
   "source": [
    "The progress and results should be availaible in OpenAI fine-tuning website while logging in to the same account of the API used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
